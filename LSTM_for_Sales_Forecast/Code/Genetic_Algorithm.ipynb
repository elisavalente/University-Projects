{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import keras\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "# Multilayer Perceptron\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.merge import concatenate\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalized=0,file_name=None):\n",
    "    col_names = ['Month', 'Advertising', 'Sales', 'erro1', 'erro2', 'erro3', 'erro4']\n",
    "    stocks = pd.read_csv(\"2advertising-and-sales-data-36-co.csv\",sep=\",\", header=0,names=col_names)  # fica numa especie de tabela exactamente como estava no csv (1350 linhas,7 colunas)\n",
    "    df = pd.DataFrame(stocks)  # neste caso não vai fazer nada\n",
    "    date_split = df['Month'].str.split('-').str  # não vai servir para nada\n",
    "    df['Ano'], df['Month'] = date_split  # não vai servir para nada\n",
    "    df.drop(df.columns[[3, 4, 5, 6, 7]], axis=1, inplace=True)  # vou só ficar com as colunas 1 e 2 TAMBÉM PODEMOS QUERER A 0\n",
    "    df = df.drop(df.index[[36, 37]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_GOOGL_stock_dataset():\n",
    "    stock_name = 'advertising'\n",
    "    return get_stock_data(stock_name,0,\"C:/Users/Elisa Valente/Desktop/4º ano/2semestre/Sistemas Autónomos/ComputerVision/2advertising-and-sales-data-36-co.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processar_GOOGL_stock_dataset(df):\n",
    "    df['Advertising'] = df['Advertising']\n",
    "    df['Sales'] = df['Sales']\n",
    "\n",
    "    conversion = {\n",
    "        'Jan': 1,\n",
    "        'Feb': 2,\n",
    "        'Mar': 3,\n",
    "        'Apr': 4,\n",
    "        'May': 5,\n",
    "        'Jun': 6,\n",
    "        'Jul': 7,\n",
    "        'Aug': 8,\n",
    "        'Sep': 9,\n",
    "        'Oct': 10,\n",
    "        'Nov': 11,\n",
    "        'Dec': 12,\n",
    "    }\n",
    "\n",
    "\n",
    "    # Categorizar meses to_categorize\n",
    "    # acrescnetar estações do ano\n",
    "    # categorizar dias com significado crescente\n",
    "\n",
    "    meses = []\n",
    "    for line in df['Month']:\n",
    "        meses.append(conversion[line])\n",
    "    df['Month'] = meses\n",
    "    df = pd.get_dummies(df, columns=['Month'])\n",
    "\n",
    "    estacoes = [4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3,\n",
    "                4]\n",
    "    df['Estacoes'] = estacoes\n",
    "    df = pd.get_dummies(df, columns=['Estacoes'])\n",
    "\n",
    "    ano = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "    #df['Ano'] = ano\n",
    "    #df = pd.get_dummies(df, columns=['Ano'])\n",
    "    #print(df)\n",
    "\n",
    "    dias = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31, 31, 28, 31,\n",
    "            30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    #df['Dias'] = dias\n",
    "    #df['Dias'] = df['Dias']/10\n",
    "\n",
    "    col_list = list(df)\n",
    "    col_list[1], col_list[18] = col_list[18], col_list[1]\n",
    "    df= df.ix[:, col_list]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df_dados, janela):\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    mat_dados = df_dados.as_matrix()#converter dataframe para matriz (lista com lista de cada registo)\n",
    "    #print(mat_dados)\n",
    "    tam_sequencia = janela + 1\n",
    "    res = []\n",
    "    for i in range(len(mat_dados) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        res.append(mat_dados[i: i + tam_sequencia])\n",
    "    res = np.array(res) #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    qt_casos_treino = int(round(0.667 * res.shape[0])) #2/3% passam a ser casos de treino\n",
    "    #print(qt_casos_treino, res.shape[0])\n",
    "    train = res[:qt_casos_treino, :]\n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,-1] #para ir buscar o último atributo para a lista dos labels\n",
    "    x_test = res[qt_casos_treino:, :-1]\n",
    "    y_test = res[qt_casos_treino:, -1][:,-1]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_test, y_test = shuffle(x_test, y_test)\n",
    "    #print(x_train)\n",
    "    return [x_train, y_train, x_test, y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(janela,dropout1,dropout2,dropout3,lstm_nodes1,lstm_nodes2,dense_nodes,relu_alpha):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(int(2**lstm_nodes1), activation='relu',input_shape=(janela, 19), return_sequences=True,kernel_constraint=max_norm(3), recurrent_constraint=max_norm(3), bias_constraint=max_norm(3))))\n",
    "    model.add(Dropout(dropout1))\n",
    "    model.add(LSTM(int(2**lstm_nodes2), activation='relu', return_sequences=False,kernel_constraint=max_norm(3), recurrent_constraint=max_norm(3), bias_constraint=max_norm(3)))\n",
    "    model.add(Dropout(dropout2))\n",
    "    #model.add(Dense(125, activation='relu'))\n",
    "    model.add(Dense(int(2**dense_nodes)))\n",
    "    model.add(LeakyReLU(alpha=relu_alpha))\n",
    "    model.add(Dropout(dropout3))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessFunction(model, b_size, e_pochs):\n",
    "    df = load_GOOGL_stock_dataset()\n",
    "    df = pre_processar_GOOGL_stock_dataset(df)\n",
    "    #print(\"df\", df.shape)\n",
    "    #print(\"tamanho do dataset\", len(df))\n",
    "    janela = 3 #tamanho da Janela deslizante 22\n",
    "    X_train, y_train, X_test, y_test = load_data(df, janela)# o df[::-1] é o df por ordem inversa\n",
    "    #print(\"X_train\", X_train.shape)\n",
    "    #print(\"y_train\", y_train.shape)\n",
    "    #print(\"X_test\", X_test.shape)\n",
    "    #print(\"y_test\", y_test.shape)\n",
    "    #model = build_model(janela)\n",
    "    #model.fit(X_train, y_train, batch_size=512, epochs=2000, validation_split=0.1,verbose=0)\n",
    "    history = model.fit(X_train, y_train, batch_size = int(b_size),epochs=int(e_pochs), validation_split= 0.01,verbose=0)\n",
    "    #print_history_loss(history)\n",
    "    #print_model(model,\"lstm_model.png\")\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    #print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    #print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    #print(model.metrics_names)\n",
    "    #p = model.predict(X_test)\n",
    "    #predic = np.squeeze(np.asarray(p)) #para transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    #print_series_prediction(y_test,predic)\n",
    "    return math.sqrt(testScore[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_fitness(janela,new_population, pop_size):\n",
    "    scores = []\n",
    "    for i in range(pop_size):\n",
    "        model = build_model(janela,new_population[i][0],new_population[i][1],new_population[i][2],new_population[i][3],new_population[i][4],new_population[i][5],new_population[i][6])\n",
    "        score = fitnessFunction(model,new_population[i][7],new_population[i][8])\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mating_pool(population, scores, num_parents):\n",
    "    parents = numpy.empty((num_parents, len(population[0])))\n",
    "    for parent_num in range(num_parents):\n",
    "        min_fitness_idx = numpy.where(scores == numpy.min(scores))\n",
    "        min_fitness_idx = min_fitness_idx[0][0]\n",
    "        parents[parent_num,:] = population[min_fitness_idx,:]\n",
    "        scores[min_fitness_idx] = 1000\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "    for k in range(offspring_size[0]):\n",
    "         # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    idx = numpy.random.randint(0, len(offspring_crossover))\n",
    "    # The random value to be added to the gene.\n",
    "    gene_number = numpy.random.randint(0, 6, 1)\n",
    "    if (gene_number == 0):\n",
    "        offspring_crossover[idx,0] = random.uniform(0, 1)\n",
    "    elif (gene_number == 1):\n",
    "        offspring_crossover[idx,1] = random.uniform(0, 1)\n",
    "    elif (gene_number == 2):\n",
    "        offspring_crossover[idx,2] = random.uniform(0, 1)\n",
    "    elif (gene_number == 3):\n",
    "        offspring_crossover[idx,3] = random.randint(1,7)\n",
    "    elif (gene_number == 4):\n",
    "        offspring_crossover[idx,4] = random.randint(1, 7)\n",
    "    elif (gene_number == 5):\n",
    "        offspring_crossover[idx,5] = random.randint(1, 7)\n",
    "    elif (gene_number == 6):\n",
    "        offspring_crossover[idx,5] = random.uniform(0, 1)\n",
    "    elif (gene_number == 7):\n",
    "        offspring_crossover[idx,5] = random.randint(0, 20)\n",
    "    elif (gene_number == 7):\n",
    "        offspring_crossover[idx,5] = random.randint(300, 3000)\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.12533915e-01 8.53768681e-01 2.36161342e-01 7.00000000e+00\n",
      "  5.00000000e+00 6.00000000e+00 9.69331658e-01 1.10000000e+01\n",
      "  2.27400000e+03]\n",
      " [9.96996703e-01 2.98236063e-01 9.67051030e-01 3.00000000e+00\n",
      "  7.00000000e+00 4.00000000e+00 6.56641492e-01 1.10000000e+01\n",
      "  4.72000000e+02]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 7.00000000e+00 8.28764215e-01 2.00000000e+01\n",
      "  1.85200000e+03]\n",
      " [1.33600376e-01 1.01033306e-01 5.48749686e-01 3.00000000e+00\n",
      "  6.00000000e+00 2.00000000e+00 5.97654632e-03 1.90000000e+01\n",
      "  2.43600000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]\n",
      " [1.90406401e-01 6.64643982e-01 8.53038632e-01 5.00000000e+00\n",
      "  1.00000000e+00 6.00000000e+00 2.02550989e-01 1.60000000e+01\n",
      "  6.80000000e+02]\n",
      " [8.35444905e-01 5.97813812e-01 9.27373099e-02 2.00000000e+00\n",
      "  3.00000000e+00 2.00000000e+00 8.28783480e-01 1.50000000e+01\n",
      "  2.31400000e+03]]\n",
      "WARNING:tensorflow:From C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:49: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3721: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0.18595882662112878\n",
      "0.20738490506178262\n",
      "0.180291518588924\n",
      "0.17733416720476006\n",
      "0.1819351945643863\n",
      "0.17621845868616434\n",
      "0.1931120610609368\n",
      "0.18485240471023587\n",
      "Scores:\n",
      "[0.18595882662112878, 0.20738490506178262, 0.180291518588924, 0.17733416720476006, 0.1819351945643863, 0.17621845868616434, 0.1931120610609368, 0.18485240471023587]\n",
      "[[4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 7.00000000e+00 8.28764215e-01 2.00000000e+01\n",
      "  1.85200000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [1.33600376e-01 1.01033306e-01 5.48749686e-01 3.00000000e+00\n",
      "  6.00000000e+00 2.00000000e+00 5.97654632e-03 1.90000000e+01\n",
      "  2.43600000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  4.00000000e+00 3.00000000e+00 8.28764215e-01 2.00000000e+01\n",
      "  1.85200000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  6.00000000e+00 2.00000000e+00 5.97654632e-03 1.90000000e+01\n",
      "  2.43600000e+03]\n",
      " [1.33600376e-01 1.01033306e-01 5.48749686e-01 3.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]]\n",
      "0.1655496677885003\n",
      "0.17184055590119432\n",
      "0.17319912638713728\n",
      "0.20692622921896453\n",
      "0.17868743283316227\n",
      "0.17510415111438046\n",
      "0.20236663283934153\n",
      "0.18730648306422537\n",
      "Scores:\n",
      "[0.1655496677885003, 0.17184055590119432, 0.17319912638713728, 0.20692622921896453, 0.17868743283316227, 0.17510415111438046, 0.20236663283934153, 0.18730648306422537]\n",
      "[[4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 7.00000000e+00 8.28764215e-01 2.00000000e+01\n",
      "  1.85200000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  4.00000000e+00 7.00000000e+00 8.28764215e-01 2.00000000e+01\n",
      "  1.85200000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 1.09528485e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]]\n",
      "0.18119722000701596\n",
      "0.18306884399340803\n",
      "0.18205142993973086\n",
      "0.17321661208813907\n",
      "0.1893631141224811\n",
      "0.1632044241832045\n",
      "0.19311644002776793\n",
      "0.19337394929155322\n",
      "Scores:\n",
      "[0.18119722000701596, 0.18306884399340803, 0.18205142993973086, 0.17321661208813907, 0.1893631141224811, 0.1632044241832045, 0.19311644002776793, 0.19337394929155322]\n",
      "[[6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 1.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  2.00000000e+00 2.00000000e+00 9.17917964e-02 5.00000000e+00\n",
      "  1.40600000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]]\n",
      "0.1760192319768784\n",
      "0.18411904122343714\n",
      "0.19188548447732845\n",
      "0.1747525046688208\n",
      "0.1789496864661971\n",
      "0.19321194239516992\n",
      "0.17864825499165743\n",
      "0.1801685859049799\n",
      "Scores:\n",
      "[0.1760192319768784, 0.18411904122343714, 0.19188548447732845, 0.1747525046688208, 0.1789496864661971, 0.19321194239516992, 0.17864825499165743, 0.1801685859049799]\n",
      "[[7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 1.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [7.86904138e-01 3.73382971e-01 9.55348618e-01 4.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 9.46085549e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [4.42066956e-01 3.61864216e-01 3.49407318e-01 5.00000000e+00\n",
      "  4.00000000e+00 1.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]\n",
      " [6.59740154e-01 6.74416979e-01 3.92954360e-01 2.00000000e+00\n",
      "  4.00000000e+00 5.00000000e+00 4.79733987e-01 8.00000000e+00\n",
      "  2.64500000e+03]]\n",
      "0.1913536252450387\n",
      "0.17112411856581042\n",
      "0.18879792877537124\n",
      "0.1831624667146351\n",
      "0.1879427668972346\n",
      "0.1886849511395473\n"
     ]
    }
   ],
   "source": [
    "pop_size = 8\n",
    "genes_number = 9 # Numero de genes\n",
    "gen_numbers = 10  # Numero de geracoes\n",
    "num_parents = int(pop_size/2)\n",
    "offspring_number = int(pop_size/2)\n",
    "janela=3\n",
    "\n",
    "offspring_size = (offspring_number, genes_number)\n",
    "new_population = []\n",
    "\n",
    "for i in range(0,pop_size):\n",
    "    n_lstms = random.randint(1, 1)\n",
    "    pop = [random.uniform(0, 1),random.uniform(0, 1),random.uniform(0, 1),random.randint(1,7),random.randint(1, 7),random.randint(1, 7),random.uniform(0, 1), random.randint(0, 20),random.randint(300, 3000)]\n",
    "    new_population.append(pop)\n",
    "    \n",
    "new_population = np.array(new_population)\n",
    "\n",
    "for generation in range(gen_numbers):\n",
    "    if(generation!=(gen_numbers-1)):\n",
    "        print(new_population)\n",
    "        scores = pop_fitness(janela, new_population, pop_size)\n",
    "        print('Scores:' )\n",
    "        print(scores)\n",
    "        parents = select_mating_pool(new_population, scores, num_parents)\n",
    "        #print('Parents:')\n",
    "        #print(parents)\n",
    "        offspring = crossover(parents, offspring_size)\n",
    "        offspring_mutation = mutation(offspring)\n",
    "        #print('Offspring:')\n",
    "        #print(offspring)\n",
    "\n",
    "        new_population[0:parents.shape[0]] = parents\n",
    "        new_population[parents.shape[0]:pop_size] = offspring_mutation\n",
    "    else:\n",
    "        print(new_population)\n",
    "        scores = pop_fitness(janela, new_population, pop_size)\n",
    "        print('Scores:' )\n",
    "        print(scores)\n",
    "\n",
    "    \n",
    "print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
