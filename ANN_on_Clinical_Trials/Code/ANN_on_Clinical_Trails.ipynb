{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "## Predict whether a mammogram mass is benign or malignant\n",
    "\n",
    "We'll be using the \"mammographic masses\" public dataset.\n",
    "\n",
    "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
    "\n",
    "\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "   \n",
    "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
    "\n",
    "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
    "\n",
    "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. \n",
    "\n",
    "Build a better way to interpret them through supervised machine learning.\n",
    "\n",
    "## Your assignment\n",
    "\n",
    "Apply Artificial Neural Network supervised machine learning techniques to this data set and validate it by applying K-Fold cross validation (K=10).\n",
    "\n",
    "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
    "\n",
    "Many optimization techniques provide the means of \"hyperparameters\" to be tuned (e.g. Genetic Algorithms). Once you identify a promising approach, see if you can make it even better by tuning its hyperparameters.\n",
    "\n",
    "Below it's described the set of steps that outline the development of this project, with some guidance and hints. If you're up for a real challenge, try doing this project from scratch in a new, clean notebook!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin: prepare your data\n",
    "\n",
    "Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"mammographic_masses.data.txt\")\n",
    "data = data.drop([\"BI-RADS\"],axis=1)\n",
    "data.head()\n",
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "data = data.replace(\"?\",numpy.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.463059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         severity\n",
       "count  961.000000\n",
       "mean     0.463059\n",
       "std      0.498893\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          5\n",
       "shape       31\n",
       "margin      48\n",
       "density     76\n",
       "severity     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop([\"severity\"],axis=1)\n",
    "target = data['severity']\n",
    "features = features.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "featuresScaled = scaler.transform(features)\n",
    "features = pd.DataFrame(featuresScaled,columns = data.columns[:-1],index=features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in training data and test data. Test data will be used to a final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "featModeling, featEvaluation, targetModeling, targetEvaluation = train_test_split(features, target, test_size=0.05, random_state=24)\n",
    "\n",
    "#dataModeling = featModeling.join(targetModeling)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "def fitnessFunction(featModeling,classifier):\n",
    "    kf = KFold(10)\n",
    "    model_score = []\n",
    "    for trainIndex, testIndex in kf.split(featModeling):\n",
    "        final_preds  = []\n",
    "        trainFeatures = featModeling.iloc[trainIndex]\n",
    "        trainTarget = targetModeling.iloc[trainIndex]\n",
    "\n",
    "        testFeatures = featModeling.iloc[testIndex]\n",
    "        testTarget = targetModeling.iloc[testIndex]\n",
    "\n",
    "        input_func = tf.estimator.inputs.pandas_input_fn(x=trainFeatures,y=trainTarget,batch_size=20,shuffle=True)\n",
    "        classifier.train(input_fn=input_func,steps=500)\n",
    "        pred_fn = tf.estimator.inputs.pandas_input_fn(x=testFeatures,batch_size=len(testFeatures),shuffle=False)\n",
    "        note_predictions = list(classifier.predict(input_fn=pred_fn))\n",
    "        for pred in note_predictions:\n",
    "            final_preds.append(pred['class_ids'][0])\n",
    "        matrix = confusion_matrix(testTarget,final_preds)\n",
    "        recall_rate = (matrix[1][1])/(matrix[1][1]+matrix[1][0])\n",
    "        accuracy = (matrix[0][0]+matrix[1][1])/len(testTarget)\n",
    "        model_score.append((accuracy*0.8)+(recall_rate*0.2))\n",
    "\n",
    "    model_score_mean = np.mean(model_score)\n",
    "    return model_score_mean\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 4 6 1]\n",
      " [7 1 6 0]\n",
      " [8 1 5 0]\n",
      " [7 1 5 1]\n",
      " [8 5 4 1]\n",
      " [3 6 7 0]\n",
      " [9 4 5 0]\n",
      " [4 3 8 0]\n",
      " [4 1 3 1]\n",
      " [3 3 3 0]\n",
      " [9 3 8 0]\n",
      " [1 3 8 0]\n",
      " [8 1 3 1]\n",
      " [4 1 2 0]\n",
      " [3 3 5 0]\n",
      " [2 4 2 1]\n",
      " [8 2 5 0]\n",
      " [4 3 5 1]\n",
      " [4 6 3 1]\n",
      " [2 2 3 1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "max_layers = 10\n",
    "max_nodes = 7\n",
    "\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "shape = tf.feature_column.numeric_column(\"shape\")\n",
    "margin = tf.feature_column.numeric_column(\"margin\")\n",
    "density = tf.feature_column.numeric_column(\"density\")\n",
    "\n",
    "feat_cols = [age,shape,margin,density]\n",
    "\n",
    "new_population = []\n",
    "pop_size=20\n",
    "\n",
    "layers = numpy.random.randint(low=1, high=max_layers, size=pop_size)\n",
    "nodes = numpy.random.randint(low=1, high=max_nodes, size=pop_size)\n",
    "learn_rate = numpy.random.randint(low=2, high=9, size=pop_size)\n",
    "act_func = numpy.random.randint(low=0, high=2, size=pop_size)\n",
    "\n",
    "for i in range(pop_size):\n",
    "    new_population.append([layers[i],nodes[i],learn_rate[i],act_func[i]])\n",
    "\n",
    "new_population = np.array(new_population)\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_fitness(featModeling, new_population, pop_size):\n",
    "    scores = []\n",
    "    for i in range(pop_size):\n",
    "        hiddenNodes = numpy.repeat([2**new_population[i][1]],new_population[i][0])\n",
    "\n",
    "        learn_rate = 1/ (10** (new_population[i][2]))\n",
    "\n",
    "\n",
    "        if(new_population[i][3]==0):\n",
    "            actFunction=tf.nn.relu6\n",
    "        else:\n",
    "            actFunction=tf.nn.sigmoid\n",
    "\n",
    "\n",
    "        print(new_population[i])\n",
    "        classifier = tf.estimator.DNNClassifier(hidden_units=hiddenNodes, \n",
    "                                                n_classes=2,\n",
    "                                                feature_columns=feat_cols, \n",
    "                                                activation_fn=actFunction, \n",
    "                                                optimizer=tf.train.GradientDescentOptimizer(learn_rate)\n",
    "                                               )\n",
    "\n",
    "        score = fitnessFunction(featModeling, classifier)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mating_pool(population, scores, num_parents):\n",
    "    parents = numpy.empty((num_parents, population.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(scores == numpy.max(scores))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = population[max_fitness_idx, :]\n",
    "        scores[max_fitness_idx] = 0\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        gene_number = numpy.random.randint(0, 4, 1)\n",
    "        if (gene_number == 0):\n",
    "            offspring_crossover[idx,0] = numpy.random.randint(1, max_layers, 1)\n",
    "        elif (gene_number == 1):\n",
    "            offspring_crossover[idx,1] = numpy.random.randint(1, max_nodes, 1)\n",
    "        elif (gene_number == 2):\n",
    "            offspring_crossover[idx,2] = numpy.random.randint(2, 9, 1)\n",
    "        elif (gene_number == 3):\n",
    "            offspring_crossover[idx,3] = numpy.random.randint(0, 2, 1)\n",
    "    \n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 4 6 1]\n",
      " [7 1 6 0]\n",
      " [8 1 5 0]\n",
      " [7 1 5 1]\n",
      " [8 5 4 1]\n",
      " [3 6 7 0]\n",
      " [9 4 5 0]\n",
      " [4 3 8 0]\n",
      " [4 1 3 1]\n",
      " [3 3 3 0]\n",
      " [9 3 8 0]\n",
      " [1 3 8 0]\n",
      " [8 1 3 1]\n",
      " [4 1 2 0]\n",
      " [3 3 5 0]\n",
      " [2 4 2 1]\n",
      " [8 2 5 0]\n",
      " [4 3 5 1]\n",
      " [4 6 3 1]\n",
      " [2 2 3 1]]\n",
      "[7 4 6 1]\n",
      "[7 1 6 0]\n",
      "[8 1 5 0]\n",
      "[7 1 5 1]\n",
      "[8 5 4 1]\n",
      "[3 6 7 0]\n",
      "[9 4 5 0]\n",
      "[4 3 8 0]\n",
      "[4 1 3 1]\n",
      "[3 3 3 0]\n",
      "[9 3 8 0]\n",
      "[1 3 8 0]\n",
      "[8 1 3 1]\n",
      "[4 1 2 0]\n",
      "[3 3 5 0]\n",
      "[2 4 2 1]\n",
      "[8 2 5 0]\n",
      "[4 3 5 1]\n",
      "[4 6 3 1]\n",
      "[2 2 3 1]\n",
      "Scores:\n",
      "[0.5904836092177865, 0.4095163907822136, 0.4095163907822136, 0.5904836092177865, 0.4095163907822136, 0.46048996229187394, 0.6079462558950369, 0.5940342421291788, 0.4616239857189225, 0.7863017997637207, 0.629062564610339, 0.4962343498203386, 0.5904836092177865, 0.4095163907822136, 0.5830996130209194, 0.7754510666420151, 0.6129665937832764, 0.4095163907822136, 0.45508601103537805, 0.41099416528913146]\n",
      "Antes: \n",
      "[[3. 3. 2. 1.]\n",
      " [2. 4. 8. 0.]\n",
      " [9. 3. 5. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [9. 4. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [2. 4. 8. 0.]\n",
      " [9. 3. 5. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [9. 4. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 5. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [9. 4. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [9. 4. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 3. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 4. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 3. 5. 1.]\n",
      " [7. 1. 3. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 3. 5. 1.]\n",
      " [7. 1. 6. 1.]\n",
      " [8. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Antes: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 3. 5. 1.]\n",
      " [7. 1. 6. 1.]\n",
      " [9. 1. 5. 0.]\n",
      " [3. 3. 3. 0.]]\n",
      "Depois: \n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 3. 5. 1.]\n",
      " [7. 1. 6. 1.]\n",
      " [9. 1. 5. 0.]\n",
      " [3. 3. 5. 0.]]\n",
      "Parents:\n",
      "[[3. 3. 3. 0.]\n",
      " [2. 4. 2. 1.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [9. 4. 5. 0.]\n",
      " [4. 3. 8. 0.]\n",
      " [7. 4. 6. 1.]\n",
      " [7. 1. 5. 1.]\n",
      " [8. 1. 3. 1.]\n",
      " [3. 3. 5. 0.]]\n",
      "Offspring:\n",
      "[[1. 3. 2. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [9. 1. 8. 0.]\n",
      " [4. 6. 6. 1.]\n",
      " [7. 3. 5. 1.]\n",
      " [7. 1. 6. 1.]\n",
      " [9. 1. 5. 0.]\n",
      " [3. 3. 5. 0.]]\n",
      "Finished!\n",
      "[[3 3 3 0]\n",
      " [2 4 2 1]\n",
      " [9 3 8 0]\n",
      " [8 2 5 0]\n",
      " [9 4 5 0]\n",
      " [4 3 8 0]\n",
      " [7 4 6 1]\n",
      " [7 1 5 1]\n",
      " [8 1 3 1]\n",
      " [3 3 5 0]\n",
      " [1 3 2 1]\n",
      " [8 4 8 0]\n",
      " [9 3 6 0]\n",
      " [8 2 5 1]\n",
      " [9 1 8 0]\n",
      " [4 6 6 1]\n",
      " [7 3 5 1]\n",
      " [7 1 6 1]\n",
      " [9 1 5 0]\n",
      " [3 3 5 0]]\n",
      "[3 3 3 0]\n",
      "[2 4 2 1]\n",
      "[9 3 8 0]\n",
      "[8 2 5 0]\n",
      "[9 4 5 0]\n",
      "[4 3 8 0]\n",
      "[7 4 6 1]\n",
      "[7 1 5 1]\n",
      "[8 1 3 1]\n",
      "[3 3 5 0]\n",
      "[1 3 2 1]\n",
      "[8 4 8 0]\n",
      "[9 3 6 0]\n",
      "[8 2 5 1]\n",
      "[9 1 8 0]\n",
      "[4 6 6 1]\n",
      "[7 3 5 1]\n",
      "[7 1 6 1]\n",
      "[9 1 5 0]\n",
      "[3 3 5 0]\n",
      "Scores:\n",
      "[0.7852262337184601, 0.8067465279570468, 0.4095163907822136, 0.6730350005747381, 0.5819965848611058, 0.5606061489770123, 0.4095163907822136, 0.5904836092177865, 0.5540733528075301, 0.5116751163022648, 0.7922845656599784, 0.5904836092177865, 0.5677400059572413, 0.5904836092177865, 0.4095163907822136, 0.4095163907822136, 0.4095163907822136, 0.5904836092177865, 0.4095163907822136, 0.4542936795943821]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [7. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [7. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [7. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [7. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [7. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 5. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 0.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 0.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 6. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 0.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 5. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Depois: \n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 0.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 5. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 2. 1.]\n",
      " [3. 3. 3. 0.]\n",
      " [8. 2. 5. 0.]\n",
      " [7. 1. 5. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [8. 2. 5. 1.]\n",
      " [7. 1. 6. 1.]\n",
      " [9. 4. 5. 0.]\n",
      " [9. 3. 6. 0.]]\n",
      "Offspring:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 5. 0.]\n",
      " [3. 3. 5. 0.]\n",
      " [9. 2. 5. 1.]\n",
      " [6. 1. 8. 0.]\n",
      " [8. 4. 7. 1.]\n",
      " [8. 2. 6. 0.]\n",
      " [7. 1. 5. 0.]\n",
      " [9. 4. 5. 0.]\n",
      " [9. 3. 2. 1.]]\n",
      "Finished!\n",
      "[[2 4 2 1]\n",
      " [1 3 2 1]\n",
      " [3 3 3 0]\n",
      " [8 2 5 0]\n",
      " [7 1 5 1]\n",
      " [8 4 8 0]\n",
      " [8 2 5 1]\n",
      " [7 1 6 1]\n",
      " [9 4 5 0]\n",
      " [9 3 6 0]\n",
      " [2 4 2 0]\n",
      " [1 3 5 0]\n",
      " [3 3 5 0]\n",
      " [9 2 5 1]\n",
      " [6 1 8 0]\n",
      " [8 4 7 1]\n",
      " [8 2 6 0]\n",
      " [7 1 5 0]\n",
      " [9 4 5 0]\n",
      " [9 3 2 1]]\n",
      "[2 4 2 1]\n",
      "[1 3 2 1]\n",
      "[3 3 3 0]\n",
      "[8 2 5 0]\n",
      "[7 1 5 1]\n",
      "[8 4 8 0]\n",
      "[8 2 5 1]\n",
      "[7 1 6 1]\n",
      "[9 4 5 0]\n",
      "[9 3 6 0]\n",
      "[2 4 2 0]\n",
      "[1 3 5 0]\n",
      "[3 3 5 0]\n",
      "[9 2 5 1]\n",
      "[6 1 8 0]\n",
      "[8 4 7 1]\n",
      "[8 2 6 0]\n",
      "[7 1 5 0]\n",
      "[9 4 5 0]\n",
      "[9 3 2 1]\n",
      "Scores:\n",
      "[0.7942738839321024, 0.813276327147638, 0.7972356660489498, 0.37516084806197136, 0.4095163907822136, 0.6705651512918374, 0.4095163907822136, 0.5904836092177865, 0.6669644096349222, 0.695660048074114, 0.8135676769021132, 0.5873548046983045, 0.5904836092177865, 0.4095163907822136, 0.4095163907822136, 0.5904836092177865, 0.4230050067961305, 0.4095163907822136, 0.55390323002881, 0.475800064913989]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [2. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [8. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 1. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 5. 5. 0.]\n",
      " [3. 3. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 5. 5. 0.]\n",
      " [3. 5. 7. 1.]\n",
      " [8. 4. 2. 0.]]\n",
      "Depois: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 5. 5. 0.]\n",
      " [3. 5. 7. 1.]\n",
      " [8. 4. 2. 1.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [3. 3. 3. 0.]\n",
      " [2. 4. 2. 1.]\n",
      " [9. 3. 6. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [9. 4. 5. 0.]\n",
      " [7. 1. 6. 1.]\n",
      " [3. 3. 5. 0.]\n",
      " [8. 4. 7. 1.]]\n",
      "Offspring:\n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [7. 4. 6. 0.]\n",
      " [9. 3. 8. 0.]\n",
      " [5. 4. 5. 0.]\n",
      " [9. 4. 6. 1.]\n",
      " [7. 5. 5. 0.]\n",
      " [3. 5. 7. 1.]\n",
      " [8. 4. 2. 1.]]\n",
      "Finished!\n",
      "[[2 4 2 0]\n",
      " [1 3 2 1]\n",
      " [3 3 3 0]\n",
      " [2 4 2 1]\n",
      " [9 3 6 0]\n",
      " [8 4 8 0]\n",
      " [9 4 5 0]\n",
      " [7 1 6 1]\n",
      " [3 3 5 0]\n",
      " [8 4 7 1]\n",
      " [4 4 2 1]\n",
      " [1 3 3 0]\n",
      " [9 3 2 1]\n",
      " [7 4 6 0]\n",
      " [9 3 8 0]\n",
      " [5 4 5 0]\n",
      " [9 4 6 1]\n",
      " [7 5 5 0]\n",
      " [3 5 7 1]\n",
      " [8 4 2 1]]\n",
      "[2 4 2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 1]\n",
      "[3 3 3 0]\n",
      "[2 4 2 1]\n",
      "[9 3 6 0]\n",
      "[8 4 8 0]\n",
      "[9 4 5 0]\n",
      "[7 1 6 1]\n",
      "[3 3 5 0]\n",
      "[8 4 7 1]\n",
      "[4 4 2 1]\n",
      "[1 3 3 0]\n",
      "[9 3 2 1]\n",
      "[7 4 6 0]\n",
      "[9 3 8 0]\n",
      "[5 4 5 0]\n",
      "[9 4 6 1]\n",
      "[7 5 5 0]\n",
      "[3 5 7 1]\n",
      "[8 4 2 1]\n",
      "Scores:\n",
      "[0.8165713383332474, 0.8119483524123728, 0.7435258327665524, 0.7057115468583542, 0.4095163907822136, 0.5890324362772519, 0.418947928927859, 0.4095163907822136, 0.39275186076817487, 0.4095163907822136, 0.4793898085037326, 0.7422583286608978, 0.4414151249594288, 0.5644240267603763, 0.4095163907822136, 0.25558495615231636, 0.5904836092177865, 0.5530047893116993, 0.4095163907822136, 0.4421746186303149]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [2. 4. 6. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [2. 4. 6. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [2. 4. 6. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [2. 4. 6. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 6. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 8. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 6. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 5. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 3. 0.]\n",
      " [7. 5. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 3. 0.]\n",
      " [7. 6. 2. 1.]\n",
      " [4. 4. 2. 0.]]\n",
      "Depois: \n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 3. 0.]\n",
      " [7. 6. 2. 1.]\n",
      " [4. 1. 2. 0.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [2. 4. 2. 1.]\n",
      " [9. 4. 6. 1.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 6. 0.]\n",
      " [7. 5. 5. 0.]\n",
      " [4. 4. 2. 1.]]\n",
      "Offspring:\n",
      "[[2. 4. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [9. 4. 3. 0.]\n",
      " [8. 4. 8. 0.]\n",
      " [7. 4. 3. 0.]\n",
      " [7. 6. 2. 1.]\n",
      " [4. 1. 2. 0.]]\n",
      "Finished!\n",
      "[[2 4 2 0]\n",
      " [1 3 2 1]\n",
      " [3 3 3 0]\n",
      " [1 3 3 0]\n",
      " [2 4 2 1]\n",
      " [9 4 6 1]\n",
      " [8 4 8 0]\n",
      " [7 4 6 0]\n",
      " [7 5 5 0]\n",
      " [4 4 2 1]\n",
      " [2 4 2 1]\n",
      " [9 3 3 0]\n",
      " [3 3 3 0]\n",
      " [1 1 2 1]\n",
      " [2 4 3 1]\n",
      " [9 4 3 0]\n",
      " [8 4 8 0]\n",
      " [7 4 3 0]\n",
      " [7 6 2 1]\n",
      " [4 1 2 0]]\n",
      "[2 4 2 0]\n",
      "[1 3 2 1]\n",
      "[3 3 3 0]\n",
      "[1 3 3 0]\n",
      "[2 4 2 1]\n",
      "[9 4 6 1]\n",
      "[8 4 8 0]\n",
      "[7 4 6 0]\n",
      "[7 5 5 0]\n",
      "[4 4 2 1]\n",
      "[2 4 2 1]\n",
      "[9 3 3 0]\n",
      "[3 3 3 0]\n",
      "[1 1 2 1]\n",
      "[2 4 3 1]\n",
      "[9 4 3 0]\n",
      "[8 4 8 0]\n",
      "[7 4 3 0]\n",
      "[7 6 2 1]\n",
      "[4 1 2 0]\n",
      "Scores:\n",
      "[0.8131941838339998, 0.8106146507179117, 0.7840518044206132, 0.7627157714107695, 0.7693526994397445, 0.5904836092177865, 0.5288205272961297, 0.6310751727070121, 0.5468842953047254, 0.5226355079519638, 0.7717734151435814, 0.7849518036707936, 0.7622669620780786, 0.7844410839304362, 0.6481220181074068, 0.6107024540706686, 0.3357715040403805, 0.7237622025811163, 0.48344044141512504, 0.40901006166828957]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [1. 2. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [1. 2. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [7. 4. 2. 0.]]\n",
      "Depois: \n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [1. 2. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [7. 4. 4. 0.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [9. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [3. 3. 3. 0.]\n",
      " [2. 4. 2. 1.]\n",
      " [2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [7. 4. 3. 0.]]\n",
      "Offspring:\n",
      "[[2. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [9. 3. 8. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [2. 3. 2. 1.]\n",
      " [2. 6. 2. 1.]\n",
      " [2. 4. 3. 1.]\n",
      " [1. 2. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [7. 4. 4. 0.]]\n",
      "Finished!\n",
      "[[2 4 2 0]\n",
      " [1 3 2 1]\n",
      " [9 3 3 0]\n",
      " [1 1 2 1]\n",
      " [3 3 3 0]\n",
      " [2 4 2 1]\n",
      " [2 4 2 1]\n",
      " [1 3 3 0]\n",
      " [3 3 3 0]\n",
      " [7 4 3 0]\n",
      " [2 1 2 1]\n",
      " [1 4 3 0]\n",
      " [9 3 8 1]\n",
      " [1 1 3 0]\n",
      " [2 3 2 1]\n",
      " [2 6 2 1]\n",
      " [2 4 3 1]\n",
      " [1 2 3 0]\n",
      " [5 3 3 0]\n",
      " [7 4 4 0]]\n",
      "[2 4 2 0]\n",
      "[1 3 2 1]\n",
      "[9 3 3 0]\n",
      "[1 1 2 1]\n",
      "[3 3 3 0]\n",
      "[2 4 2 1]\n",
      "[2 4 2 1]\n",
      "[1 3 3 0]\n",
      "[3 3 3 0]\n",
      "[7 4 3 0]\n",
      "[2 1 2 1]\n",
      "[1 4 3 0]\n",
      "[9 3 8 1]\n",
      "[1 1 3 0]\n",
      "[2 3 2 1]\n",
      "[2 6 2 1]\n",
      "[2 4 3 1]\n",
      "[1 2 3 0]\n",
      "[5 3 3 0]\n",
      "[7 4 4 0]\n",
      "Scores:\n",
      "[0.816475929865746, 0.8141288158776465, 0.7186880819378676, 0.7782528363719201, 0.7629734994203549, 0.7165409429248132, 0.7364699715974663, 0.7963660280985982, 0.7523350541429732, 0.7842451390594588, 0.729147818570295, 0.791410039679277, 0.4095163907822136, 0.7976380605048996, 0.7323283922623494, 0.7479293333055188, 0.6652991277793314, 0.7538395857769651, 0.7746931624690544, 0.7057282216815827]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 2. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 2. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 2. 0.]]\n",
      "Depois: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 2. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 5. 0.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [5. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]]\n",
      "Offspring:\n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 5. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [7. 4. 5. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [5. 2. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 5. 0.]]\n",
      "Finished!\n",
      "[[2 4 2 0]\n",
      " [1 3 2 1]\n",
      " [1 1 3 0]\n",
      " [1 3 3 0]\n",
      " [1 4 3 0]\n",
      " [7 4 3 0]\n",
      " [1 1 2 1]\n",
      " [5 3 3 0]\n",
      " [3 3 3 0]\n",
      " [1 2 3 0]\n",
      " [4 4 2 1]\n",
      " [1 3 5 0]\n",
      " [1 6 3 0]\n",
      " [4 3 3 0]\n",
      " [1 4 3 0]\n",
      " [7 4 5 1]\n",
      " [1 1 3 0]\n",
      " [5 2 3 0]\n",
      " [3 3 3 0]\n",
      " [1 2 5 0]]\n",
      "[2 4 2 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 1]\n",
      "[1 1 3 0]\n",
      "[1 3 3 0]\n",
      "[1 4 3 0]\n",
      "[7 4 3 0]\n",
      "[1 1 2 1]\n",
      "[5 3 3 0]\n",
      "[3 3 3 0]\n",
      "[1 2 3 0]\n",
      "[4 4 2 1]\n",
      "[1 3 5 0]\n",
      "[1 6 3 0]\n",
      "[4 3 3 0]\n",
      "[1 4 3 0]\n",
      "[7 4 5 1]\n",
      "[1 1 3 0]\n",
      "[5 2 3 0]\n",
      "[3 3 3 0]\n",
      "[1 2 5 0]\n",
      "Scores:\n",
      "[0.8143535132302508, 0.7921315420451077, 0.7645539819938132, 0.8048581607867087, 0.7724788275624989, 0.7236818861344375, 0.8088936287844597, 0.7567980025431942, 0.7517715017898018, 0.7770389513537379, 0.4995975332684194, 0.29295637566868915, 0.8075368077415922, 0.6937700010881246, 0.763154377793609, 0.5904836092177865, 0.7559871725425273, 0.6135479432675204, 0.7886181695691096, 0.7209919811065644]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 1. 3. 1.]\n",
      " [1. 4. 2. 0.]]\n",
      "Depois: \n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 1. 3. 1.]\n",
      " [1. 4. 2. 1.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 3. 2. 1.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 2. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]]\n",
      "Offspring:\n",
      "[[4. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 3. 4. 1.]\n",
      " [1. 3. 7. 0.]\n",
      " [4. 3. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 1. 3. 1.]\n",
      " [1. 4. 2. 1.]]\n",
      "Finished!\n",
      "[[2 4 2 0]\n",
      " [1 1 2 1]\n",
      " [1 6 3 0]\n",
      " [1 3 3 0]\n",
      " [1 3 2 1]\n",
      " [3 3 3 0]\n",
      " [1 2 3 0]\n",
      " [1 4 3 0]\n",
      " [1 1 3 0]\n",
      " [1 4 3 0]\n",
      " [4 4 2 1]\n",
      " [1 3 3 0]\n",
      " [1 6 3 0]\n",
      " [1 3 4 1]\n",
      " [1 3 7 0]\n",
      " [4 3 3 0]\n",
      " [1 4 3 0]\n",
      " [1 6 3 0]\n",
      " [1 1 3 1]\n",
      " [1 4 2 1]]\n",
      "[2 4 2 0]\n",
      "[1 1 2 1]\n",
      "[1 6 3 0]\n",
      "[1 3 3 0]\n",
      "[1 3 2 1]\n",
      "[3 3 3 0]\n",
      "[1 2 3 0]\n",
      "[1 4 3 0]\n",
      "[1 1 3 0]\n",
      "[1 4 3 0]\n",
      "[4 4 2 1]\n",
      "[1 3 3 0]\n",
      "[1 6 3 0]\n",
      "[1 3 4 1]\n",
      "[1 3 7 0]\n",
      "[4 3 3 0]\n",
      "[1 4 3 0]\n",
      "[1 6 3 0]\n",
      "[1 1 3 1]\n",
      "[1 4 2 1]\n",
      "Scores:\n",
      "[0.8127536300938125, 0.790020876363224, 0.7882711374022169, 0.7574714955266509, 0.8100591872526381, 0.800158433239767, 0.7275679676606175, 0.7889011353929745, 0.7065501106974778, 0.7537884386131333, 0.544407659850698, 0.7328196614067122, 0.8017824017507312, 0.42920727626880595, 0.5904836092177865, 0.709553885422365, 0.785770342024142, 0.805590856365261, 0.6847332147844447, 0.8124877586812096]\n",
      "Antes: \n",
      "[[2. 4. 2. 1.]\n",
      " [1. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [1. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [1. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 6. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 2. 0.]]\n",
      "Antes: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 6. 0.]\n",
      " [1. 6. 3. 1.]\n",
      " [1. 4. 2. 0.]]\n",
      "Depois: \n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 6. 0.]\n",
      " [1. 6. 3. 1.]\n",
      " [9. 4. 2. 0.]]\n",
      "Parents:\n",
      "[[2. 4. 2. 0.]\n",
      " [1. 4. 2. 1.]\n",
      " [1. 3. 2. 1.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 3. 3. 0.]\n",
      " [1. 1. 2. 1.]\n",
      " [1. 4. 3. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [1. 4. 3. 0.]]\n",
      "Offspring:\n",
      "[[3. 4. 2. 1.]\n",
      " [7. 4. 2. 1.]\n",
      " [2. 3. 3. 0.]\n",
      " [1. 6. 8. 0.]\n",
      " [1. 6. 3. 0.]\n",
      " [3. 6. 2. 1.]\n",
      " [1. 1. 3. 0.]\n",
      " [1. 4. 6. 0.]\n",
      " [1. 6. 3. 1.]\n",
      " [9. 4. 2. 0.]]\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "genes_number = 4 # Numero de genes\n",
    "gen_numbers = 8  # Numero de geracoes\n",
    "num_parents = int(pop_size/2)\n",
    "offspring_number = int(pop_size/2)\n",
    "\n",
    "offspring_size = (offspring_number, genes_number)\n",
    "\n",
    "for generation in range(gen_numbers):\n",
    "    print(new_population)\n",
    "    scores = pop_fitness(featModeling, new_population, pop_size)\n",
    "    print('Scores:' )\n",
    "    print(scores)\n",
    "    parents = select_mating_pool(new_population, scores, num_parents)\n",
    "    offspring = crossover(parents, offspring_size)\n",
    "    offspring_mutation = mutation(offspring)\n",
    "    print('Parents:')\n",
    "    print(parents)\n",
    "    print('Offspring:')\n",
    "    print(offspring)\n",
    "    \n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation\n",
    "\n",
    "    \n",
    "    print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 2 16]]\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(hidden_units=[8], \n",
    "                                                n_classes=2,\n",
    "                                                feature_columns=feat_cols, \n",
    "                                                activation_fn=tf.nn.sigmoid, \n",
    "                                                optimizer=tf.train.GradientDescentOptimizer(1/(10**2))\n",
    "                                               )\n",
    "\n",
    "\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=featModeling,y=targetModeling,batch_size=20,shuffle=True)\n",
    "classifier.train(input_fn=input_func,steps=500)\n",
    "\n",
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=featEvaluation,batch_size=len(featEvaluation),shuffle=False)\n",
    "note_predictions = list(classifier.predict(input_fn=pred_fn))\n",
    "final_preds  = []\n",
    "for pred in note_predictions:\n",
    "    final_preds.append(pred['class_ids'][0])\n",
    "matrix = confusion_matrix(targetEvaluation,final_preds)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
